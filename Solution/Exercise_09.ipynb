{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise_09.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "_BsEJesxACRz"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-JwSwNW9QmT"
      },
      "source": [
        "\n",
        "# CUDA Exercise 09\n",
        "> You should try to implement your own solution for matrix multiplication, and try to parallelize the computation.\n",
        "\n",
        "This Jupyter Notebook can also be open by the google colab, so you don't have to buy a PC with a graphic card to play with CUDA. To launch the Google Colab, please click the below Icon.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg#left)](https://colab.research.google.com/github/SuperChange001/CUDA_Learning/blob/main/Solution/Exercise_09.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOEai4hb95Ip"
      },
      "source": [
        "## Initialize the CUDA dev environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqmwwI7H5nDx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b484e91-696c-4992-d0a5-e734417b246f"
      },
      "source": [
        "# clone the code repo,\n",
        "# !pip install git+git://github.com/depctg/nvcc4jupyter.git\n",
        "# %load_ext nvcc_plugin\n",
        "!pip install nvcc4jupyter\n",
        "%load_ext nvcc4jupyter"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n",
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmp5gf4notc\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2Zeyyo4_gNH"
      },
      "source": [
        "## Check the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6PT4QpR6oxt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d43161b0-0124-4cd0-80a9-26c4b9c15b43"
      },
      "source": [
        "!lsb_release -a\n",
        "!nvcc --version\n",
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No LSB modules are available.\n",
            "Distributor ID:\tUbuntu\n",
            "Description:\tUbuntu 22.04.4 LTS\n",
            "Release:\t22.04\n",
            "Codename:\tjammy\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n",
            "Sat Jun  7 03:22:48 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TF6KTYqE_n7H"
      },
      "source": [
        "## Matrix Multiplication - Implimentation 01"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ev5_BW1z80S3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f56f92a-61f6-45ec-ccae-abb57b33d51a"
      },
      "source": [
        "%%writefile matrix_mul_01.cu\n",
        "// %%cu\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void matrix_mul(int *matrix_a, int *matrix_b, int *matrix_c,int matrix_a_row,int matrix_a_column,int matrix_b_column){\n",
        "    int matrix_c_element = 0;\n",
        "    for (int i = 0; i < matrix_a_column; i++){\n",
        "      matrix_c_element += matrix_a[(threadIdx.x/matrix_b_column)*matrix_a_column+i] * matrix_b[threadIdx.x%matrix_b_column+i*matrix_b_column];\n",
        "    }\n",
        "    matrix_c[threadIdx.x]= matrix_c_element;\n",
        "}\n",
        "\n",
        "int main(int argc, char *argv[]){\n",
        "\n",
        "    //===========================================================================\n",
        "    // Below, there are three example case, which you should only uncomment one\n",
        "    // of them, to run the test.\n",
        "    /* Example 1\n",
        "    int matrix_a[16] = {5,0,34,21,7,17,-12,28,8,-3,-3,-3,0,-3,5,9};\n",
        "    int matrix_a_row = 4;\n",
        "    int matrix_a_column = 4;\n",
        "    int matrix_b[16] = {0,16,24,-90,-23,0,11,1,3,3,0,3,66,7,8,0};\n",
        "    int matrix_b_row = 4;\n",
        "    int matrix_b_column = 4;\n",
        "    */\n",
        "\n",
        "    /* Example 2\n",
        "    int matrix_a[12] = {12,6,22,7,17,-12,36,9,9,0,-1,-2};\n",
        "    int matrix_a_row = 4;\n",
        "    int matrix_a_column = 3;\n",
        "    int matrix_b[15] = {0,16,24,-1,4,-23,0,11,1,4,3,3,0,3,4};\n",
        "    int matrix_b_row = 3;\n",
        "    int matrix_b_column = 5;\n",
        "    */\n",
        "\n",
        "    // random initialization of larger matrixes\n",
        "    // matrix_a_row * matrix_b_column <= 1024\n",
        "    int matrix_a_row = 50;\n",
        "    int matrix_a_column = 30;\n",
        "    int *matrix_a = (int*) malloc(sizeof(int) * (matrix_a_row * matrix_a_column));\n",
        "    for(int i = 0; i < matrix_a_row; i++){\n",
        "        for(int j = 0; j < matrix_a_column; j++)\n",
        "        {\n",
        "            int index = i * matrix_a_column+j;\n",
        "            matrix_a[index] = 1;\n",
        "        }\n",
        "    }\n",
        "    int matrix_b_row = 30;\n",
        "    int matrix_b_column = 20;\n",
        "    int *matrix_b = (int*) malloc(sizeof(int) * (matrix_b_row * matrix_b_column));\n",
        "    for(int i = 0; i < matrix_b_row; i++){\n",
        "        for(int j = 0; j < matrix_b_column; j++)\n",
        "        {\n",
        "            int index = i * matrix_b_column+j;\n",
        "            matrix_b[index] = 2;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    //===========================================================================\n",
        "\n",
        "    int *matrix_c = (int*) malloc(sizeof(int) * (matrix_a_row * matrix_b_column));\n",
        "    int *d_matrix_a, *d_matrix_b, *d_matrix_c;\n",
        "\n",
        "    cudaMalloc((void**)&d_matrix_a,sizeof(int) * (matrix_a_row * matrix_a_column));\n",
        "    cudaMalloc((void**)&d_matrix_b,sizeof(int) * (matrix_b_row * matrix_b_column));\n",
        "    cudaMalloc((void**)&d_matrix_c,sizeof(int) * (matrix_a_row * matrix_b_column));\n",
        "\n",
        "    cudaMemcpy(d_matrix_a, matrix_a, sizeof(int) * (matrix_a_row * matrix_a_column), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_matrix_b, matrix_b, sizeof(int) * (matrix_b_row * matrix_b_column), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // implement 100 times for getting average execution time\n",
        "    for(int i=0; i<100;i++){\n",
        "      matrix_mul<<<1,matrix_a_row * matrix_b_column>>>(d_matrix_a, d_matrix_b, d_matrix_c, matrix_a_row,matrix_a_column, matrix_b_column);\n",
        "    }\n",
        "\n",
        "    cudaMemcpy(matrix_c, d_matrix_c,sizeof(int) * (matrix_a_row * matrix_b_column), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // print matrix_c to check correction\n",
        "    for(int i = 0; i < matrix_a_row; i++){\n",
        "        for(int j = 0; j < matrix_b_column; j++){\n",
        "            int index = i * matrix_b_column +j;\n",
        "            printf(\"%d, \",matrix_c[index]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    cudaFree(d_matrix_c);\n",
        "    cudaFree(d_matrix_b);\n",
        "    cudaFree(d_matrix_a);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrix_mul_01.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BsEJesxACRz"
      },
      "source": [
        "## Evaluation to collect enough information for the benchmark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjisNLsazjUT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c1e3a4f-8e23-4ec7-b98c-0fbbf8511708"
      },
      "source": [
        "!nvcc -o matrix_mul_01 matrix_mul_01.cu\n",
        "!nvprof ./matrix_mul_01\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==993== NVPROF is profiling process 993, command: ./matrix_mul_01\n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "==993== Profiling application: ./matrix_mul_01\n",
            "==993== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   50.98%  2.5290us         1  2.5290us  2.5290us  2.5290us  [CUDA memcpy DtoH]\n",
            "                   49.02%  2.4320us         2  1.2160us     864ns  1.5680us  [CUDA memcpy HtoD]\n",
            "      API calls:   81.85%  229.31ms         3  76.436ms  6.0980us  229.29ms  cudaMalloc\n",
            "                   17.37%  48.660ms       100  486.60us     205ns  48.638ms  cudaLaunchKernel\n",
            "                    0.37%  1.0356ms         1  1.0356ms  1.0356ms  1.0356ms  cuDeviceGetPCIBusId\n",
            "                    0.28%  797.19us         3  265.73us  6.8480us  743.10us  cudaMemcpy\n",
            "                    0.07%  191.13us         3  63.708us  5.1830us  163.74us  cudaFree\n",
            "                    0.05%  144.59us       114  1.2680us     110ns  55.632us  cuDeviceGetAttribute\n",
            "                    0.01%  16.036us         1  16.036us  16.036us  16.036us  cuDeviceGetName\n",
            "                    0.00%  8.3960us         1  8.3960us  8.3960us  8.3960us  cudaDeviceSynchronize\n",
            "                    0.00%  1.2760us         3     425ns     166ns     866ns  cuDeviceGetCount\n",
            "                    0.00%  1.0280us         2     514ns     218ns     810ns  cuDeviceGet\n",
            "                    0.00%     623ns         1     623ns     623ns     623ns  cuDeviceTotalMem\n",
            "                    0.00%     466ns         1     466ns     466ns     466ns  cuModuleGetLoadingMode\n",
            "                    0.00%     290ns         1     290ns     290ns     290ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LefKVzj4VUV"
      },
      "source": [
        "## Matrix Multiplication - Implimentation 02"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZvzZt8d4UpL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dc6b248-d20b-4b62-864e-ff39d3509781"
      },
      "source": [
        "%%writefile matrix_mul_02.cu\n",
        "//%%cu\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void matrix_mul(int *matrix_a, int *matrix_b, int *matrix_c,int matrix_a_row,int matrix_a_column,int matrix_b_column){\n",
        "    int matrix_c_element = 0;\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    for (int i = 0; i < matrix_a_column; i++){\n",
        "      matrix_c_element += matrix_a[(tid/matrix_b_column)*matrix_a_column+i] * matrix_b[tid%matrix_b_column+i*matrix_b_column];\n",
        "    }\n",
        "    matrix_c[tid]= matrix_c_element;\n",
        "}\n",
        "\n",
        "int main(int argc, char *argv[]){\n",
        "\n",
        "    //===========================================================================\n",
        "    // Below, there are three example case, which you should only uncomment one\n",
        "    // of them, to run the test.\n",
        "\n",
        "    /* Example 1\n",
        "    int matrix_a[16] = {5,0,34,21,7,17,-12,28,8,-3,-3,-3,0,-3,5,9};\n",
        "    int matrix_a_row = 4;\n",
        "    int matrix_a_column = 4;\n",
        "    int matrix_b[16] = {0,16,24,-90,-23,0,11,1,3,3,0,3,66,7,8,0};\n",
        "    int matrix_b_row = 4;\n",
        "    int matrix_b_column = 4;\n",
        "    */\n",
        "\n",
        "    /* Example 2\n",
        "    int matrix_a[12] = {12,6,22,7,17,-12,36,9,9,0,-1,-2};\n",
        "    int matrix_a_row = 4;\n",
        "    int matrix_a_column = 3;\n",
        "    int matrix_b[15] = {0,16,24,-1,4,-23,0,11,1,4,3,3,0,3,4};\n",
        "    int matrix_b_row = 3;\n",
        "    int matrix_b_column = 5;\n",
        "    */\n",
        "\n",
        "\n",
        "    // random initialization of larger matrixes\n",
        "    // matrix_a_row as number of blocks\n",
        "    // matrix_b_column as number of threads per block\n",
        "    int matrix_a_row = 50;\n",
        "    int matrix_a_column = 30;\n",
        "    int *matrix_a = (int*) malloc(sizeof(int) * (matrix_a_row * matrix_a_column));\n",
        "    for(int i = 0; i < matrix_a_row; i++){\n",
        "        for(int j = 0; j < matrix_a_column; j++)\n",
        "        {\n",
        "            int index = i * matrix_a_column+j;\n",
        "            matrix_a[index] = 1;\n",
        "        }\n",
        "    }\n",
        "    int matrix_b_row = 30;\n",
        "    int matrix_b_column = 20;\n",
        "    int *matrix_b = (int*) malloc(sizeof(int) * (matrix_b_row * matrix_b_column));\n",
        "    for(int i = 0; i < matrix_b_row; i++){\n",
        "        for(int j = 0; j < matrix_b_column; j++)\n",
        "        {\n",
        "            int index = i * matrix_b_column+j;\n",
        "            matrix_b[index] = 2;\n",
        "        }\n",
        "    }\n",
        "    //===========================================================================\n",
        "\n",
        "\n",
        "    int *matrix_c = (int*) malloc(sizeof(int) * (matrix_a_row * matrix_b_column));\n",
        "    int *d_matrix_a, *d_matrix_b, *d_matrix_c;\n",
        "\n",
        "    cudaMalloc((void**)&d_matrix_a,sizeof(int) * (matrix_a_row * matrix_a_column));\n",
        "    cudaMalloc((void**)&d_matrix_b,sizeof(int) * (matrix_b_row * matrix_b_column));\n",
        "    cudaMalloc((void**)&d_matrix_c,sizeof(int) * (matrix_a_row * matrix_b_column));\n",
        "\n",
        "    cudaMemcpy(d_matrix_a, matrix_a, sizeof(int) * (matrix_a_row * matrix_a_column), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_matrix_b, matrix_b, sizeof(int) * (matrix_b_row * matrix_b_column), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // implement 100 times for getting average execution time\n",
        "    for(int i=0; i<100;i++){\n",
        "    matrix_mul<<<matrix_a_row,matrix_b_column>>>(d_matrix_a, d_matrix_b, d_matrix_c, matrix_a_row,matrix_a_column, matrix_b_column);\n",
        "\n",
        "    //for comparison with 01.cu\n",
        "    //matrix_mul<<<1,matrix_a_row * matrix_b_column>>>(d_matrix_a, d_matrix_b, d_matrix_c, matrix_a_row,matrix_a_column, matrix_b_column);\n",
        "    }\n",
        "\n",
        "    cudaMemcpy(matrix_c, d_matrix_c,sizeof(int) * (matrix_a_row * matrix_b_column), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // print matrix_c to check correction\n",
        "    for(int i = 0; i < matrix_a_row; i++){\n",
        "        for(int j = 0; j < matrix_b_column; j++){\n",
        "            int index = i * matrix_b_column +j;\n",
        "            printf(\"%d, \",matrix_c[index]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    cudaFree(d_matrix_c);\n",
        "    cudaFree(d_matrix_b);\n",
        "    cudaFree(d_matrix_a);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrix_mul_02.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKNir-yF_F_8"
      },
      "source": [
        "## Evaluation to collect enough information for the benchmark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s61EVRmqQ0RF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb722fba-af00-44a3-a470-bad044d970fe"
      },
      "source": [
        "!nvcc -o matrix_mul_02 matrix_mul_02.cu\n",
        "!nvprof ./matrix_mul_02"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==1087== NVPROF is profiling process 1087, command: ./matrix_mul_02\n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "==1087== Profiling application: ./matrix_mul_02\n",
            "==1087== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   50.96%  2.5600us         1  2.5600us  2.5600us  2.5600us  [CUDA memcpy DtoH]\n",
            "                   49.04%  2.4640us         2  1.2320us     864ns  1.6000us  [CUDA memcpy HtoD]\n",
            "      API calls:   95.69%  197.79ms         3  65.931ms  3.5720us  197.78ms  cudaMalloc\n",
            "                    4.12%  8.5149ms       100  85.148us     214ns  8.4921ms  cudaLaunchKernel\n",
            "                    0.07%  143.95us       114  1.2620us     120ns  57.796us  cuDeviceGetAttribute\n",
            "                    0.07%  134.87us         3  44.955us  4.5530us  114.34us  cudaFree\n",
            "                    0.03%  63.122us         3  21.040us  7.4010us  32.294us  cudaMemcpy\n",
            "                    0.02%  32.719us         1  32.719us  32.719us  32.719us  cuDeviceGetName\n",
            "                    0.00%  7.3730us         1  7.3730us  7.3730us  7.3730us  cudaDeviceSynchronize\n",
            "                    0.00%  5.8200us         1  5.8200us  5.8200us  5.8200us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.4050us         3     468ns     163ns  1.0350us  cuDeviceGetCount\n",
            "                    0.00%     829ns         2     414ns     160ns     669ns  cuDeviceGet\n",
            "                    0.00%     598ns         1     598ns     598ns     598ns  cuDeviceTotalMem\n",
            "                    0.00%     399ns         1     399ns     399ns     399ns  cuModuleGetLoadingMode\n",
            "                    0.00%     270ns         1     270ns     270ns     270ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    }
  ]
}