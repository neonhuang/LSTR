{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise_09.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "_BsEJesxACRz"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-JwSwNW9QmT"
      },
      "source": [
        "\n",
        "# CUDA Exercise 09\n",
        "> You should try to implement your own solution for matrix multiplication, and try to parallelize the computation.\n",
        "\n",
        "This Jupyter Notebook can also be open by the google colab, so you don't have to buy a PC with a graphic card to play with CUDA. To launch the Google Colab, please click the below Icon.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg#left)](https://colab.research.google.com/github/SuperChange001/CUDA_Learning/blob/main/Solution/Exercise_09.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOEai4hb95Ip"
      },
      "source": [
        "## Initialize the CUDA dev environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqmwwI7H5nDx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddf374d2-4c2c-440f-b943-9a2dca913502"
      },
      "source": [
        "# clone the code repo,\n",
        "!pip install nvcc4jupyter\n",
        "%load_ext nvcc4jupyter\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n",
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmpns2qpb9c\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2Zeyyo4_gNH"
      },
      "source": [
        "## Check the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6PT4QpR6oxt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "382277b3-7b40-4db9-df47-b3588988be1d"
      },
      "source": [
        "!lsb_release -a\n",
        "!nvcc --version\n",
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No LSB modules are available.\n",
            "Distributor ID:\tUbuntu\n",
            "Description:\tUbuntu 22.04.4 LTS\n",
            "Release:\t22.04\n",
            "Codename:\tjammy\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n",
            "Thu Jun  5 12:07:10 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TF6KTYqE_n7H"
      },
      "source": [
        "## Matrix Multiplication - Implimentation 01"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ev5_BW1z80S3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0085424-034c-4e27-e38d-39b0d06f8a7f"
      },
      "source": [
        "%%writefile matrix_mul_01.cu\n",
        "// %%cuda\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void matrix_mul(int *matrix_a, int *matrix_b, int *matrix_c,int matrix_a_row,int matrix_a_column,int matrix_b_column){\n",
        "    int matrix_c_element = 0;\n",
        "    for (int i = 0; i < matrix_a_column; i++){\n",
        "      matrix_c_element += matrix_a[(threadIdx.x/matrix_b_column)*matrix_a_column+i] * matrix_b[threadIdx.x%matrix_b_column+i*matrix_b_column];\n",
        "    }\n",
        "    matrix_c[threadIdx.x]= matrix_c_element;\n",
        "}\n",
        "\n",
        "int main(int argc, char *argv[]){\n",
        "\n",
        "    //===========================================================================\n",
        "    // Below, there are three example case, which you should only uncomment one\n",
        "    // of them, to run the test.\n",
        "    /* Example 1\n",
        "    int matrix_a[16] = {5,0,34,21,7,17,-12,28,8,-3,-3,-3,0,-3,5,9};\n",
        "    int matrix_a_row = 4;\n",
        "    int matrix_a_column = 4;\n",
        "    int matrix_b[16] = {0,16,24,-90,-23,0,11,1,3,3,0,3,66,7,8,0};\n",
        "    int matrix_b_row = 4;\n",
        "    int matrix_b_column = 4;\n",
        "    */\n",
        "\n",
        "    /* Example 2\n",
        "    int matrix_a[12] = {12,6,22,7,17,-12,36,9,9,0,-1,-2};\n",
        "    int matrix_a_row = 4;\n",
        "    int matrix_a_column = 3;\n",
        "    int matrix_b[15] = {0,16,24,-1,4,-23,0,11,1,4,3,3,0,3,4};\n",
        "    int matrix_b_row = 3;\n",
        "    int matrix_b_column = 5;\n",
        "    */\n",
        "\n",
        "    // random initialization of larger matrixes\n",
        "    // matrix_a_row * matrix_b_column <= 1024\n",
        "    int matrix_a_row = 50;\n",
        "    int matrix_a_column = 30;\n",
        "    int *matrix_a = (int*) malloc(sizeof(int) * (matrix_a_row * matrix_a_column));\n",
        "    for(int i = 0; i < matrix_a_row; i++){\n",
        "        for(int j = 0; j < matrix_a_column; j++)\n",
        "        {\n",
        "            int index = i * matrix_a_column+j;\n",
        "            matrix_a[index] = 1;\n",
        "        }\n",
        "    }\n",
        "    int matrix_b_row = 30;\n",
        "    int matrix_b_column = 20;\n",
        "    int *matrix_b = (int*) malloc(sizeof(int) * (matrix_b_row * matrix_b_column));\n",
        "    for(int i = 0; i < matrix_b_row; i++){\n",
        "        for(int j = 0; j < matrix_b_column; j++)\n",
        "        {\n",
        "            int index = i * matrix_b_column+j;\n",
        "            matrix_b[index] = 2;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    //===========================================================================\n",
        "\n",
        "    int *matrix_c = (int*) malloc(sizeof(int) * (matrix_a_row * matrix_b_column));\n",
        "    int *d_matrix_a, *d_matrix_b, *d_matrix_c;\n",
        "\n",
        "    cudaMalloc((void**)&d_matrix_a,sizeof(int) * (matrix_a_row * matrix_a_column));\n",
        "    cudaMalloc((void**)&d_matrix_b,sizeof(int) * (matrix_b_row * matrix_b_column));\n",
        "    cudaMalloc((void**)&d_matrix_c,sizeof(int) * (matrix_a_row * matrix_b_column));\n",
        "\n",
        "    cudaMemcpy(d_matrix_a, matrix_a, sizeof(int) * (matrix_a_row * matrix_a_column), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_matrix_b, matrix_b, sizeof(int) * (matrix_b_row * matrix_b_column), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // implement 100 times for getting average execution time\n",
        "    for(int i=0; i<100;i++){\n",
        "      matrix_mul<<<1,matrix_a_row * matrix_b_column>>>(d_matrix_a, d_matrix_b, d_matrix_c, matrix_a_row,matrix_a_column, matrix_b_column);\n",
        "    }\n",
        "\n",
        "    cudaMemcpy(matrix_c, d_matrix_c,sizeof(int) * (matrix_a_row * matrix_b_column), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // print matrix_c to check correction\n",
        "    for(int i = 0; i < matrix_a_row; i++){\n",
        "        for(int j = 0; j < matrix_b_column; j++){\n",
        "            int index = i * matrix_b_column +j;\n",
        "            printf(\"%d, \",matrix_c[index]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    cudaFree(d_matrix_c);\n",
        "    cudaFree(d_matrix_b);\n",
        "    cudaFree(d_matrix_a);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matrix_mul_01.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BsEJesxACRz"
      },
      "source": [
        "## Evaluation to collect enough information for the benchmark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjisNLsazjUT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "422b2066-0b58-4ce5-b990-3e7dfd981f16"
      },
      "source": [
        "!nvcc -o matrix_mul_01 matrix_mul_01.cu\n",
        "!nvprof ./matrix_mul_01\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==1477== NVPROF is profiling process 1477, command: ./matrix_mul_01\n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "==1477== Profiling application: ./matrix_mul_01\n",
            "==1477== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   52.20%  2.6560us         1  2.6560us  2.6560us  2.6560us  [CUDA memcpy DtoH]\n",
            "                   47.80%  2.4320us         2  1.2160us     864ns  1.5680us  [CUDA memcpy HtoD]\n",
            "      API calls:   71.16%  118.77ms         3  39.590ms  6.3490us  118.74ms  cudaMalloc\n",
            "                   27.95%  46.657ms       100  466.57us     193ns  46.637ms  cudaLaunchKernel\n",
            "                    0.34%  562.13us         3  187.38us  6.8830us  509.41us  cudaMemcpy\n",
            "                    0.34%  559.24us         1  559.24us  559.24us  559.24us  cuDeviceGetPCIBusId\n",
            "                    0.11%  184.72us         3  61.573us  4.8630us  159.62us  cudaFree\n",
            "                    0.09%  151.78us       114  1.3310us     108ns  57.844us  cuDeviceGetAttribute\n",
            "                    0.01%  12.327us         1  12.327us  12.327us  12.327us  cuDeviceGetName\n",
            "                    0.00%  7.3000us         1  7.3000us  7.3000us  7.3000us  cudaDeviceSynchronize\n",
            "                    0.00%  1.3710us         3     457ns     136ns  1.0250us  cuDeviceGetCount\n",
            "                    0.00%     962ns         2     481ns     159ns     803ns  cuDeviceGet\n",
            "                    0.00%     539ns         1     539ns     539ns     539ns  cuDeviceTotalMem\n",
            "                    0.00%     462ns         1     462ns     462ns     462ns  cuModuleGetLoadingMode\n",
            "                    0.00%     274ns         1     274ns     274ns     274ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LefKVzj4VUV"
      },
      "source": [
        "## Matrix Multiplication - Implimentation 02"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZvzZt8d4UpL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93b4e9bd-01b4-4f9e-cd53-3603cece312c"
      },
      "source": [
        "%%writefile matrix_mul_02.cu\n",
        "//%%cu\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void matrix_mul(int *matrix_a, int *matrix_b, int *matrix_c,int matrix_a_row,int matrix_a_column,int matrix_b_column){\n",
        "    int matrix_c_element = 0;\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    for (int i = 0; i < matrix_a_column; i++){\n",
        "      matrix_c_element += matrix_a[(tid/matrix_b_column)*matrix_a_column+i] * matrix_b[tid%matrix_b_column+i*matrix_b_column];\n",
        "    }\n",
        "    matrix_c[tid]= matrix_c_element;\n",
        "}\n",
        "\n",
        "int main(int argc, char *argv[]){\n",
        "\n",
        "    //===========================================================================\n",
        "    // Below, there are three example case, which you should only uncomment one\n",
        "    // of them, to run the test.\n",
        "\n",
        "    /* Example 1\n",
        "    int matrix_a[16] = {5,0,34,21,7,17,-12,28,8,-3,-3,-3,0,-3,5,9};\n",
        "    int matrix_a_row = 4;\n",
        "    int matrix_a_column = 4;\n",
        "    int matrix_b[16] = {0,16,24,-90,-23,0,11,1,3,3,0,3,66,7,8,0};\n",
        "    int matrix_b_row = 4;\n",
        "    int matrix_b_column = 4;\n",
        "    */\n",
        "\n",
        "    /* Example 2\n",
        "    int matrix_a[12] = {12,6,22,7,17,-12,36,9,9,0,-1,-2};\n",
        "    int matrix_a_row = 4;\n",
        "    int matrix_a_column = 3;\n",
        "    int matrix_b[15] = {0,16,24,-1,4,-23,0,11,1,4,3,3,0,3,4};\n",
        "    int matrix_b_row = 3;\n",
        "    int matrix_b_column = 5;\n",
        "    */\n",
        "\n",
        "\n",
        "    // random initialization of larger matrixes\n",
        "    // matrix_a_row as number of blocks\n",
        "    // matrix_b_column as number of threads per block\n",
        "    int matrix_a_row = 50;\n",
        "    int matrix_a_column = 30;\n",
        "    int *matrix_a = (int*) malloc(sizeof(int) * (matrix_a_row * matrix_a_column));\n",
        "    for(int i = 0; i < matrix_a_row; i++){\n",
        "        for(int j = 0; j < matrix_a_column; j++)\n",
        "        {\n",
        "            int index = i * matrix_a_column+j;\n",
        "            matrix_a[index] = 1;\n",
        "        }\n",
        "    }\n",
        "    int matrix_b_row = 30;\n",
        "    int matrix_b_column = 20;\n",
        "    int *matrix_b = (int*) malloc(sizeof(int) * (matrix_b_row * matrix_b_column));\n",
        "    for(int i = 0; i < matrix_b_row; i++){\n",
        "        for(int j = 0; j < matrix_b_column; j++)\n",
        "        {\n",
        "            int index = i * matrix_b_column+j;\n",
        "            matrix_b[index] = 2;\n",
        "        }\n",
        "    }\n",
        "    //===========================================================================\n",
        "\n",
        "\n",
        "    int *matrix_c = (int*) malloc(sizeof(int) * (matrix_a_row * matrix_b_column));\n",
        "    int *d_matrix_a, *d_matrix_b, *d_matrix_c;\n",
        "\n",
        "    cudaMalloc((void**)&d_matrix_a,sizeof(int) * (matrix_a_row * matrix_a_column));\n",
        "    cudaMalloc((void**)&d_matrix_b,sizeof(int) * (matrix_b_row * matrix_b_column));\n",
        "    cudaMalloc((void**)&d_matrix_c,sizeof(int) * (matrix_a_row * matrix_b_column));\n",
        "\n",
        "    cudaMemcpy(d_matrix_a, matrix_a, sizeof(int) * (matrix_a_row * matrix_a_column), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_matrix_b, matrix_b, sizeof(int) * (matrix_b_row * matrix_b_column), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // implement 100 times for getting average execution time\n",
        "    for(int i=0; i<100;i++){\n",
        "    matrix_mul<<<matrix_a_row,matrix_b_column>>>(d_matrix_a, d_matrix_b, d_matrix_c, matrix_a_row,matrix_a_column, matrix_b_column);\n",
        "\n",
        "    //for comparison with 01.cu\n",
        "    //matrix_mul<<<1,matrix_a_row * matrix_b_column>>>(d_matrix_a, d_matrix_b, d_matrix_c, matrix_a_row,matrix_a_column, matrix_b_column);\n",
        "    }\n",
        "\n",
        "    cudaMemcpy(matrix_c, d_matrix_c,sizeof(int) * (matrix_a_row * matrix_b_column), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // print matrix_c to check correction\n",
        "    for(int i = 0; i < matrix_a_row; i++){\n",
        "        for(int j = 0; j < matrix_b_column; j++){\n",
        "            int index = i * matrix_b_column +j;\n",
        "            printf(\"%d, \",matrix_c[index]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    cudaFree(d_matrix_c);\n",
        "    cudaFree(d_matrix_b);\n",
        "    cudaFree(d_matrix_a);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrix_mul_02.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKNir-yF_F_8"
      },
      "source": [
        "## Evaluation to collect enough information for the benchmark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s61EVRmqQ0RF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34f4ff64-a6a1-4765-9332-f298622b9637"
      },
      "source": [
        "!nvcc -o matrix_mul_02 matrix_mul_02.cu\n",
        "!nvprof ./matrix_mul_02"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==1613== NVPROF is profiling process 1613, command: ./matrix_mul_02\n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
            "==1613== Profiling application: ./matrix_mul_02\n",
            "==1613== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   50.96%  2.5600us         1  2.5600us  2.5600us  2.5600us  [CUDA memcpy DtoH]\n",
            "                   49.04%  2.4640us         2  1.2320us     864ns  1.6000us  [CUDA memcpy HtoD]\n",
            "      API calls:   91.06%  103.24ms         3  34.413ms  9.6500us  103.22ms  cudaMalloc\n",
            "                    8.56%  9.7085ms       100  97.085us     230ns  9.6848ms  cudaLaunchKernel\n",
            "                    0.16%  177.66us         3  59.218us  4.5320us  156.93us  cudaFree\n",
            "                    0.12%  137.02us       114  1.2010us     105ns  57.391us  cuDeviceGetAttribute\n",
            "                    0.08%  87.038us         3  29.012us  9.6880us  45.193us  cudaMemcpy\n",
            "                    0.01%  11.552us         1  11.552us  11.552us  11.552us  cuDeviceGetName\n",
            "                    0.01%  8.1030us         1  8.1030us  8.1030us  8.1030us  cudaDeviceSynchronize\n",
            "                    0.01%  5.8540us         1  5.8540us  5.8540us  5.8540us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.2710us         3     757ns     149ns  1.9000us  cuDeviceGetCount\n",
            "                    0.00%  1.1670us         2     583ns     158ns  1.0090us  cuDeviceGet\n",
            "                    0.00%     575ns         1     575ns     575ns     575ns  cuDeviceTotalMem\n",
            "                    0.00%     440ns         1     440ns     440ns     440ns  cuModuleGetLoadingMode\n",
            "                    0.00%     294ns         1     294ns     294ns     294ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    }
  ]
}